# 原生代码解读

​	原生代码指FPDB原作者的那个项目。

# normal-ssb/experiment溯源

+ 来源于README.md的`Run`模块，指明是`normal-ssb-experiment`
+ ExperimentMain.cpp：主要是最后一个else，会分析所有的参数，然后在`argc < 5`处传入mainTest
+ Tests.cpp：将参数转化为对应的实体，传入executeSql，比较重要的是mode实体(仅有fullPullup, fullPushdown, pullupCaching, hybridCaching，无hybridCachingLast)，实际上里面啥定义都没有，仅仅是用于区分不同的实体
+ ExperimentUtil.cpp：主要调用Interpreter的各种方法，包括clearOperatorGraph、parse，然后使用interpreter的`getCachingPolicy()->onNewQuery(), getOperatorGraph()->boot/start/join()`来执行
+ OperatorGraph.cpp：是上述boot、start、join的使用处。粗看之下，感觉boot、start、join与新的FPDB代码比较类似

## Interpreter.cpp

+ 本处继承event\_based\_actor的是OperatorActor，其反映机制也与新的POpActor类似
+ parse：前面一大段都是在使用antlr4来将sql转化为logicalPlan，然后使用`plan::Planner::generate`来生成physicalPlan，将所有的physicaloperator扔到operatorGraph\_中(OperatorGraph.cpp中定义类型)

## Planner.cpp

+ generate：主要依次读取logicalPlan的所有operator(视为producer)，将producer、consumer、mode传入wireUp方法，生成所有的physical operator并对应连接，再形成physicalPlan中

  + logicalProducer：要连接的logical producer
  + logicalConsumer：要连接的logical consumer
  + logicalToPhysical_map：从logical -> physical的映射
  + wiredLogicalProducers：已经与它的consumer连接好的logical producer队列，避免重复连接
  + allPhysicalOperators：用来存储所有生成的physical operator
  + mode：即pullup等模式

+ toPhysicalOperators：得到logical operators对应的若干个physical operators，更新logicalToPhysical\_map与allPhysicalOperators

  + aggregate：numConcurrentUnits\_个aggregate以及一个reduce(会提前连起来，consumer是reduce)
  + collate：只有一个collate
  + group：类似aggregate，有numConcurrentUnits\_个group以及一个reduce
  + join：有JoinParallelDegree个build与probe，一一对应连接(前者为producer)

  + project：numConcurrentUnits\_个project
  + ~~fileScan：partitions个fileScan~~ 不是真正的scan operator
  + S3SelectScanLogicalOperator：这似乎才是真正的scan operator。会根据不同mode返回不同的physical operators。感觉这里的scan是cache、pullup、pushdown的精髓
    + 它的toOperators除了会生成自己所需的所有operators外，还会填充streamOutPhysicalOperators\_，而这会在Planner的wireUp中被使用，filsScan里面却没这个，所以说fileScan应该不是生效的scan
    
    + fullPullup：生成S3Get(csv，S3Select为parquet)，若没有filter则stream out为S3Get，否则为连接在S3Get后面的filter
    
    + fullPushdown：生成S3Select，无stream out(实际上stream out就是所有的S3Select)
    
    + pullupCaching：每一个scan都会有一个S3Get(csv，S3Select为parquet)、一个cacheLoad、一个merge。cacheLoad在Hit时会直接把数据传给merge，即它为merge的left producer；在miss时，会转给S3Select去读取(to cache)，即S3Select的producer为cacheLoad，此时S3Select亦为merge的right producer。若需要filter，则会将merge作为producer连接filter。最后再连接project，此时stream out为project。
    
    + hybridCaching：如下图
    
      <img src="./imgs/hybrid caching.png" style="zoom:35%;" />
  
+ wireUp：将首先，找出所有logical producer对应的physical stream out，即该流程最后一系列处理数据流的operator

  + join：显然为probe阶段的operator
  + aggregate：若数目大于1，则为reduce；否则就是aggregate
  + group：若数目大于1，则为reduce；否则就是group
  + project：就是project operator
  + scan：即S3SelectScanLogicalOperator，pushdown下为S3Select，其余为对应模式下计算出来的streamOutPhysicalOperators
  + collate：producer不可能为collate

  然后，根据consumer的类型，连接stream out与consumer的stream in

  + join：若producer为left，则stream in为join build

    + 若build数目大于1，则对于每一个stream out，我们先连接一个shuffle，再将shuffle与所有的build连接
    + 否则直接将每一个stream out与build连接

    若producer为right，则stream in为probe

    + 若probe数目大于1，则对于每一个stream out，我们先连接一个shuffle，再将shuffle与所有的probe连接
    + 否则直接将每一个stream out与probe连接

  + aggregate：会根据stream out里面operator的数目设置aggregate的numConcurrentUnits\_，之后再将stream out与aggregate一一连接

  + group：同上，也是设置numConcurrentUnits\_后将stream out与group一一连接
  + project：同上，也是设置numConcurrentUnits\_后将stream out与project一一连接
  + scan：consumer不可能为scan
  + collate：仅有一个，故只需要把所有的stream out与collate进行连接

## OperatorGraph.cpp

+ boot：为每一个operator生成actorHandle(反映的机制为OperatorActor)。注意到这里没有任何remote spawn
+ start：开始计时，设置所有operator为未完成。发送connect message进行连接，发送start message启动operator
+ join：在root收到所有complete信息后停止计时

## OperatorActor.cpp

+ 基本上是调用operator.on\_receive()方法

## CacheLoad.cpp

+ StartMessage：调用CacheHelper::requestLoadSegmentsFromCache，将需要的segmentKeys发送出去(对象？)，再得到LoadResponseMessage的回应
+ LoadResponseMessage：