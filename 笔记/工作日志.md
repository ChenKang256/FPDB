# 工作日志



# 2022/07/19

+ 更新filescanpop.cpp中的东西，自测一下，告知师兄！
  + 测一下`‘|’ and ','`：确实不行，会报错。原先的代码没有该问题，因为有这句话：`csvTableFormat->getFieldDelimiter()`
  + 自测不了：缺少`name(), table_->getSchema(), outputSchema`
+ remove all `ifdef __AVX2__`，有报错(S3)可以改CMake或代码，same
  + FileScanPOp.cpp：移除了ifdef
  + FileScanPOp.h：移除了ifdef
  + S3SelectPOp.h：移除了ifdef
  + S3SelectPOp.cpp：移除了ifdef与部分代码
  + S3GetPOp.h：移除了ifdef
  + S3GetPOp.cpp：移除了ifdef与部分代码
  + CSVToArrowSIMDChunkParser.h/.cpp：不需要管，涉及前六个文件的内容已删去
  + CSVToArrowSIMDStreamParser.h/.cpp：同上
  + SIMDParserHelper.h/.cpp：涉及到上面两组CSV文件，不需要管
  + 修改了fpdb-tuple下CMakeLists.txt的第44(CSVToArrowSIMDStreamParser)、46行(CSVToArrowSIMDChunkParser)、45行(SIMDParserHelper)

# 2022/07/20-2022/07/21

+ 统计CSV的算子数目、比例等情况。注意到，当前是pushdown-only的状态，所有的计算只在存储节点上运行。
  + 3与7比较类似，时间与比例都比较接近
  + 7与8形式相似，但是8显著慢于7，注意到8多了一个sum运算，猜测是sum运算开销太大导致速度下降
  + 7、8与9形式相似，但是9显著慢于前二者，这是因为前二者对时间有很强的限制，大大缩小了lineitem的范围，而lineitem作为最大的一个table，对性能影响比较显著，而9一方面hashjoin的范围很大，另一方面sum的求值范围很大，导致速度非常慢
  + 去除1的聚合，从33降低到17；去除8的所有sum，能将运行时间从34降到22；去除9的sum，能将运行时间从45降到26；去除12的sum，能将运行时间从9.8降到9.7。这能够说明sum对运行速度存在影响，并且sum需要的规模越大，对运行时间的影响也越大(百分比)。
  + 结论：普通的运算只要不涉及聚合运算与过于复杂的select、where、order by、group by等，速度都比较快；而涉及到sum、avg这些聚合运算，规模越大对运行时间的影响也越大(百分比)。
  + 感觉sort应该也有很大的影响，但是大家几乎都有sort的前提下，看不出来影响有多大。。
  + 难以看出提升的百分比与算子之间的关系
+ POpActor.cpp，看懂所有operator，client-server的交互(TPCHDIstTest.cpp的debug与test有助于了解)
  + 已在代码解读中完成

# 2022/07/22-2022/07/29

+ SPGLOG写

+ 了解plan的树状结构(输出每个sql的tree)

+ **捋清楚operator是如何在node上分布的，为何能够有性能提高(代码层次)**

  + 

+ scale 1,10,20 tpch size，1/2 node是什么情况，测试每一个sql(是否能够正常完成，为啥无法完成，哪些operator导致无法完成(client？))，纯无remote(注释掉filter与file\_scan)、仅有file\_scan。可以试着改变MainTest的doctest来进行。==优先完成==，用ssb测试
  + ssb生成坑点：
    + O\_CRATE的MODE问题：现在open如果使用了O\_CREAT，必须在后面给权限0777，否则会报错(bm\_utils.c的tbl\_open，retcode)
    + buffer overflow：修改shared.h的第120行，MAXAGG_LEN的定义，改成20。因为给的太小，所以造成overflow
  
+ scale生成：
  
  + stats.json：date不变(2557)，supplier乘上倍数，customer乘上倍数，part的200000加上600000\*log10()，lineorder接近乘上倍数
    + zoneMap.json：让lineorder按照划分数去划分lo\_orderdate，[19920101, 19980802]，2406天
    + schema.json：(这里都是指代)date = 1，supplier = 1，一个customer大概150000，一个part大概150000，一个lineorder大概150000
    + 原有的readme\_new是错误的，每次改变scale factor都必须修改，而不能简单地调用
  
  + 测试时间

    scale = 1，node = 2，有FileScan
  
    | sql名称 | 1.1  | 1.2  | 1.3  | 2.1   | 2.2   | 2.3   | 3.1   | 3.2   | 3.3  | 3.4  | 4.1   | 4.2   | 4.3   | 1    | 2    | 3    | 4    | 5    |
    | ------- | ---- | ---- | :--: | ----- | ----- | ----- | ----- | ----- | ---- | ---- | ----- | ----- | ----- | ---- | ---- | ---- | ---- | ---- |
    | 第一次  | 8.99 | 8.99 | 8.96 | 10.07 | 10.47 | 10.27 | 10.95 | 9.98  | 9.65 | 9.78 | 14.56 | 13.92 | 13.77 | 2.96 | 2.31 | 3.32 | 3.01 | 2.86 |
    | 第二次  | 9.20 | 8.90 | 9.34 | 10.37 | 10.75 | 10.39 | 10.26 | 9.74  | 9.67 | 9.28 | 14.67 | 14.19 | 13.77 | 3.01 | 2.29 | 3.23 | 2.92 | 2.81 |
    | 第三次  | 9.09 | 8.85 | 9.19 | 10.31 | 10.76 | 10.45 | 10.63 | 10.27 | 9.64 | 9.69 | 14.73 | 14.78 | 13.78 | 3.05 | 2.32 | 3.29 | 2.96 | 2.83 |
  | 平均    |      |      |      |       |       |       |       |       |      |      |       |       |       |      |      |      |      |      |
    
    scale = 10，node = 2，有FileScan
    
    | sql名称 | 1.1  | 1.2  | 1.3  | 2.1  | 2.2  | 2.3  | 3.1  | 3.2  | 3.3  | 3.4  | 4.1  | 4.2  | 4.3  | 1     | 2     | 3     | 4     | 5     |
    | ------- | ---- | ---- | :--: | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ----- | ----- | ----- | ----- |
    | 第一次  | X    | X    |  X   | X    | X    | X    | X    | X    | X    | X    | X    | X    | X    | 27.65 | 26.37 | 34.13 | 27.50 | 26.20 |
    | 第二次  |      |      |      |      |      |      |      |      |      |      |      |      |      | 27.80 | 26.58 |       |       |       |
    | 第三次  |      |      |      |      |      |      |      |      |      |      |      |      |      |       |       |       |       |       |
    |         |      |      |      |      |      |      |      |      |      |      |      |      |      |       |       |       |       |       |

# 2022/07/29-2022/07/31

+ 找出sf=10 original跑不了的原因。错误溯源定位：
  + 通过在POpActor.cpp中输出，检测到FileScan的operator无法工作。进一步发现仅有start信息
  + 通过在FileScan.cpp的start方法中输出，检测到ctx()在通知tuple的message时无法进行
  + 通过在POpContext.cpp的tell方法中输出，发现operatorActor\_->anon\_send无法正常工作，该类是POpActor。POpActor由Execution的actorSystem\_.spawn生成，而actorSystem\_在TestUtil.cpp的makeExecutor方法中生成，可能是CAF出问题了？？
  + 发现把FileScan、Shuffle、Filter都打开remoteSpawn后，可以正常工作。而单纯大概FileScan、Filter，会卡在Shuffle那里，推测是发送的压力太大或者单一节点的压力过大，导致CAF出故障。除了添加类型外，有可能能通过添加节点个数来解决该问题

# 2022/07/31-2022/08/02

+ nload/iftop 192.168.1.4\~6，看流量波动情况(有可能operator挂掉了？)
  + 用generated 1测试，发现FileScan -> Filter时，192.168.1.5/6 -> 192.168.1.4有较大的流量波动(接近100MB/s)
  + 用original 1.1测试，发现没有该现象
  + 说明很可能不是operator挂掉，而是根本就没有发出去
+ 看Execution.cpp中的boot.op->spawnOnRemote()有哪些operator是成立的
+ 新写一个message类，确定FileScan到Filter畅通
  + 新建了一个DebugMessage类
  + 在POpActor.cpp中新增了DEBUG类型，扔到on\_receive方法
  + 在POpContext中新增notifyDebug()方法，用于通知DebugMessage
  + 在FileScan.readAndSendTuples添加notifyDebug()
  + 在FilterPOp.on\_receive中新增DEBUG类型，用于证明存活
  + 在MessageSerialize.h中仿照其他message，新增DEBUG类型
  + 无法成功发送
+ 逐步确定Tuple的message情况(大小从小到大)
+ 把anon\_send换成同步的试试看

# 2022/08/02-

+ 核定在client-server在有多少个op的时候能正常工作，多少个不能(https://dl.acm.org/doi/abs/10.1145/2687357.2687363)

# 未来工作

+ message机制要改掉，改成RDMA/dpdk -> NEON -> cache/pushdown管理

